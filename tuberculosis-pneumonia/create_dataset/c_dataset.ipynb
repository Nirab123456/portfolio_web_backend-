{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: NORMAL, Total: 1583, Train: 1346, Val: 79, Test: 158\n",
      "Category: NORMAL, Total: 3500, Train: 2975, Val: 175, Test: 350\n",
      "Category: NORMAL, Total: 326, Train: 278, Val: 16, Test: 32\n",
      "Category: NORMAL, Total: 80, Train: 68, Val: 4, Test: 8\n",
      "Category: PNEUMONIA, Total: 4273, Train: 3633, Val: 213, Test: 427\n",
      "Category: UNKNOWN, Total: 1357, Train: 1155, Val: 67, Test: 135\n",
      "Category: TUBERCULOSIS, Total: 336, Train: 287, Val: 16, Test: 33\n",
      "Category: TUBERCULOSIS, Total: 58, Train: 51, Val: 2, Test: 5\n",
      "Category: TUBERCULOSIS, Total: 3499, Train: 2976, Val: 174, Test: 349\n",
      "Category: TUBERCULOSIS, Total: 304, Train: 259, Val: 15, Test: 30\n",
      "CSV file with dataset splits and metadata saved to D:\\source\\new\\data\\data\\dataset_splits_with_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from math import floor\n",
    "import pandas as pd\n",
    "\n",
    "# Define input paths for each category\n",
    "category_dirs = {\n",
    "    'NORMAL': [r\"D:\\source\\new\\data\\oct-Normal\", r\"D:\\source\\new\\data\\rsna-Normal\", r\"D:\\source\\new\\data\\shenzhen-Normal\", r\"D:\\source\\new\\data\\montgomerySet-Normal\"],\n",
    "    'PNEUMONIA': [r\"D:\\source\\new\\data\\oct-Pneumonia\"],\n",
    "    'UNKNOWN': [r\"D:\\source\\new\\data\\pavan-Unknown\"],\n",
    "    'TUBERCULOSIS': [r\"D:\\source\\new\\data\\shenzhen-TB\", r\"D:\\source\\new\\data\\montgomerySet-TB\", r\"D:\\source\\new\\data\\niaid-TB\", r\"D:\\source\\new\\data\\belarus\"]\n",
    "}\n",
    "\n",
    "# Define output directories\n",
    "dataset_dir = r\"D:\\source\\new\\data\\data\"\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Ensure the train, val, and test directories exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Split ratios\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.05\n",
    "\n",
    "# List to store metadata for the CSV\n",
    "csv_data = []\n",
    "\n",
    "def create_image_metadata(directory, label, source):\n",
    "    \"\"\"\n",
    "    Scans a directory for images and returns a list of metadata for the images (name, label, source).\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Path to the directory containing the images.\n",
    "        label (str): The label of the images (e.g., 'normal', 'tuberculosis', etc.).\n",
    "        source (str): The source of the images (e.g., 'oct', 'rsna', etc.).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of dictionaries containing metadata for each image.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\", \".gif\")):\n",
    "            data.append({\"name\": file, \"label\": label, \"source\": source})\n",
    "    return data\n",
    "\n",
    "# Iterate through input directories to create metadata and split the images\n",
    "for category, dirs in category_dirs.items():\n",
    "    category_train_dir = os.path.join(train_dir, category)\n",
    "    category_val_dir = os.path.join(val_dir, category)\n",
    "    category_test_dir = os.path.join(test_dir, category)\n",
    "\n",
    "    os.makedirs(category_train_dir, exist_ok=True)\n",
    "    os.makedirs(category_val_dir, exist_ok=True)\n",
    "    os.makedirs(category_test_dir, exist_ok=True)\n",
    "\n",
    "    # Create metadata for each directory\n",
    "    for dir in dirs:\n",
    "        if not os.path.exists(dir):\n",
    "            print(f\"Category folder not found: {dir}\")\n",
    "            continue\n",
    "\n",
    "        # Create metadata for the current directory\n",
    "        source_name = os.path.basename(dir).split('-')[0]\n",
    "        files_metadata = create_image_metadata(dir, category, source_name)\n",
    "\n",
    "        # Shuffle the files for random split\n",
    "        random.shuffle(files_metadata)\n",
    "        \n",
    "        total_files = len(files_metadata)\n",
    "        test_count = floor(total_files * test_ratio)\n",
    "        val_count = floor(total_files * val_ratio)\n",
    "        train_count = total_files - test_count - val_count\n",
    "\n",
    "        test_files = files_metadata[:test_count]\n",
    "        val_files = files_metadata[test_count:test_count + val_count]\n",
    "        train_files = files_metadata[test_count + val_count:]\n",
    "\n",
    "        print(f\"Category: {category}, Total: {total_files}, Train: {train_count}, Val: {val_count}, Test: {test_count}\")\n",
    "\n",
    "        # Copy files to corresponding directories and add metadata\n",
    "        for file_data in val_files:\n",
    "            file_name = file_data[\"name\"]\n",
    "            src_path = os.path.join(dir, file_name)\n",
    "            dest_path = os.path.join(category_val_dir, file_name)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            csv_data.append({**file_data, \"split\": \"val\"})\n",
    "\n",
    "        for file_data in test_files:\n",
    "            file_name = file_data[\"name\"]\n",
    "            src_path = os.path.join(dir, file_name)\n",
    "            dest_path = os.path.join(category_test_dir, file_name)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            csv_data.append({**file_data, \"split\": \"test\"})\n",
    "\n",
    "        for file_data in train_files:\n",
    "            file_name = file_data[\"name\"]\n",
    "            src_path = os.path.join(dir, file_name)\n",
    "            dest_path = os.path.join(category_train_dir, file_name)\n",
    "            shutil.copy(src_path, dest_path)\n",
    "            csv_data.append({**file_data, \"split\": \"train\"})\n",
    "\n",
    "# Create a Pandas DataFrame from the collected metadata\n",
    "df = pd.DataFrame(csv_data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = os.path.join(dataset_dir, \"dataset_splits_with_metadata.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"CSV file with dataset splits and metadata saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
