{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-11-21T18:27:01.853578Z",
     "iopub.status.busy": "2024-11-21T18:27:01.853256Z",
     "iopub.status.idle": "2024-11-21T18:27:07.307601Z",
     "shell.execute_reply": "2024-11-21T18:27:07.306927Z",
     "shell.execute_reply.started": "2024-11-21T18:27:01.853546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 7883, Validation set size: 33, Test set size: 1147\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Modify the create_dataset function to include \"UNKNOWN\" category\n",
    "def create_dataset(folder_path):\n",
    "    my_list = []\n",
    "    for category in ['NORMAL', 'PNEUMONIA', 'UNKNOWN', 'TUBERCULOSIS']:\n",
    "        category_path = os.path.join(folder_path, category)\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            # Ensure we're only adding image files\n",
    "            if os.path.isfile(file_path) and file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                my_list.append([file_path, category])\n",
    "    return pd.DataFrame(my_list, columns=['file_path', 'label'])\n",
    "\n",
    "# Dataset paths\n",
    "dataset_dir = r\"D:\\source\\chest_xray\"\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Create DataFrames for train, validation, and test datasets\n",
    "train_df = create_dataset(train_dir)\n",
    "val_df = create_dataset(val_dir)\n",
    "test_df = create_dataset(test_dir)\n",
    "\n",
    "# Convert labels to numeric: NORMAL -> 0, PNEUMONIA -> 1, UNKNOWN -> 2\n",
    "train_df['label'] = train_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2 , 'TUBERCULOSIS': 3})\n",
    "val_df['label'] = val_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2, 'TUBERCULOSIS': 3})\n",
    "test_df['label'] = test_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2, 'TUBERCULOSIS': 3})\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train set size: {len(train_df)}, Validation set size: {len(val_df)}, Test set size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Counts per Category:\n",
      "Train set:\n",
      "  NORMAL: 1700\n",
      "  PNEUMONIA: 3875\n",
      "  UNKNOWN: 1348\n",
      "  TUBERCULOSIS: 960\n",
      "Validation set:\n",
      "  NORMAL: 8\n",
      "  PNEUMONIA: 8\n",
      "  UNKNOWN: 9\n",
      "  TUBERCULOSIS: 8\n",
      "Test set:\n",
      "  NORMAL: 234\n",
      "  PNEUMONIA: 390\n",
      "  UNKNOWN: 446\n",
      "  TUBERCULOSIS: 77\n"
     ]
    }
   ],
   "source": [
    "# Function to count categories in a given DataFrame\n",
    "def count_categories(df, dataset_name):\n",
    "    category_counts = df['label'].value_counts()\n",
    "    print(f\"{dataset_name} set:\")\n",
    "    print(f\"  NORMAL: {category_counts.get(0, 0)}\")  # NORMAL = 0\n",
    "    print(f\"  PNEUMONIA: {category_counts.get(1, 0)}\")  # PNEUMONIA = 1\n",
    "    print(f\"  UNKNOWN: {category_counts.get(2, 0)}\")  # UNKNOWN = 2 (added the UNKNOWN category)\n",
    "    print(f\"  TUBERCULOSIS: {category_counts.get(3, 0)}\")  # TUBERCULOSIS = 3\n",
    "\n",
    "# Count and display for train, validation, and test datasets\n",
    "print(\"Image Counts per Category:\")\n",
    "count_categories(train_df, \"Train\")\n",
    "count_categories(val_df, \"Validation\")\n",
    "count_categories(test_df, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 247\n",
      "Validation dataset size: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Define Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # Image path\n",
    "        label = self.dataframe.iloc[idx, 1]     # Image label (NORMAL, PNEUMONIA, UNKNOWN)\n",
    "        img = Image.open(img_path).convert('RGB')  # Convert the image to RGB if not already\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "train_transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 for ResNet-18 input size\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(5),  # Slight rotation between -5 and +5 degrees\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "\n",
    "val_transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Assuming train_df and val_df are already created with 'file_path' and 'label' columns\n",
    "train_dataset_resnet = ImageDataset(train_df, transform=train_transform_resnet)\n",
    "val_dataset_resnet = ImageDataset(val_df, transform=val_transform_resnet)\n",
    "\n",
    "# DataLoader - For training and validation datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=batch_size, shuffle=True)\n",
    "val_loader_resnet = DataLoader(val_dataset_resnet, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Optionally print dataset sizes\n",
    "print(f\"Training dataset size: {len(train_loader_resnet)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader_resnet)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for multi-GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "# Function to prepare model for multi-GPU usage\n",
    "def prepare_model_for_multigpu(model):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Training function with history tracking and logging to text file\n",
    "def train_model_with_history(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device='cuda'):\n",
    "    # Ensure model is moved to the correct device (GPU/CPU)\n",
    "    model.to(device)\n",
    "    log_file='training_log.txt'\n",
    "    if os.path.exists(log_file):\n",
    "        os.remove(log_file)\n",
    "    # Track training and validation losses and accuracies\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Load model weights (if you're resuming from a pre-trained model)\n",
    "    if os.path.exists('model/model_29.pt'):\n",
    "        model.load_state_dict(torch.load('model/model_29.pt', map_location=device))\n",
    "        print(\"Model weights loaded successfully.\")\n",
    "    else:\n",
    "        print(\"No pre-trained weights found, starting from scratch.\")\n",
    "    \n",
    "    model_dir = 'model'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    # Open log file for writing\n",
    "    with open(log_file, 'w') as log:\n",
    "        # Log header\n",
    "        log.write(\"Epoch, Train Loss, Train Accuracy, Val Loss, Val Accuracy\\n\")\n",
    "\n",
    "        # Training loop for the specified number of epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            # Training loop\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass and optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Track running loss and accuracy\n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate training loss and accuracy\n",
    "            train_loss = running_loss / len(train_loader)\n",
    "            train_accuracy = 100 * correct / total\n",
    "            train_losses.append(train_loss)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            # Validation loop\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    val_loss += loss.item()\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    val_total += labels.size(0)\n",
    "                    val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate validation loss and accuracy\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_accuracy = 100 * val_correct / val_total\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "\n",
    "            # Print results for the epoch\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "                  f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "\n",
    "            # Log the results to the file\n",
    "            with open(log_file, 'a') as log:\n",
    "                log.write(f\"{epoch+1}, {train_loss:.4f}, {train_accuracy:.2f}, {val_loss:.4f}, {val_accuracy:.2f}\\n\")\n",
    "\n",
    "            # Save the model after every epoch (ensure the directory exists)\n",
    "            torch.save(model.state_dict(), f'{model_dir}/model_{epoch}.pt')\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "\n",
    "class_weights = [1.5, 0.5, 1.0 ,2.5]  \n",
    "# Convert class weights to a tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the weighted CrossEntropy loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {np.int64(0): np.float64(1.1592647058823529), np.int64(1): np.float64(0.5085806451612903), np.int64(2): np.float64(1.461980712166172), np.int64(3): np.float64(2.052864583333333)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Sample class distribution based on the dataset\n",
    "class_labels = np.array([0, 1, 2 , 3])  # Example class labels\n",
    "y_train = np.array([0]*1700 + [1]*3875 + [2]*1348 + [3]*960)  # Example training set distribution\n",
    "\n",
    "# Calculate class weights using sklearn\n",
    "class_weights = compute_class_weight('balanced', classes=class_labels, y=y_train)\n",
    "\n",
    "print(f\"Class weights: {dict(zip(class_labels, class_weights))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\mlweb\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rifat\\miniconda3\\envs\\mlweb\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-18 model\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 4)  # Modify for binary classification\n",
    "resnet18 = prepare_model_for_multigpu(resnet18)  # Apply multi-GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer for ResNet-18\n",
    "optimizer_resnet = optim.Adam(resnet18.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the Pretrained ResNet-18 Model\n",
    "print(\"Training Pretrained ResNet-18 Model...\")\n",
    "train_losses_resnet, val_losses_resnet, train_accuracies_resnet, val_accuracies_resnet = train_model_with_history(\n",
    "    resnet18, train_loader_resnet, val_loader_resnet, criterion, optimizer_resnet, num_epochs=60\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
