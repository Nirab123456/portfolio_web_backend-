{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Description**  \n",
    "\n",
    "#### **Images Dataset**  \n",
    "- **Author**: Pavan Sanagapati  \n",
    "- **Source**: [Images Dataset on Kaggle](https://www.kaggle.com/datasets/pavansanagapati/images-dataset/data)  \n",
    "- **Content**: This dataset contains images from various categories, including:  \n",
    "  - Bikes  \n",
    "  - Cars  \n",
    "  - Cats  \n",
    "  - Dogs  \n",
    "  - Flowers  \n",
    "  - Horses  \n",
    "  - Humans  \n",
    "- **Purpose**: The dataset is intended for tasks related to identifying *unknown* labels, making it suitable for applications in multi-class classification and open-set recognition problems.  \n",
    "\n",
    "#### **X-ray Dataset(Pneumonia-Normal)**  \n",
    "- **Author**: Paul Mooney  \n",
    "- **Source**: [Chest X-ray Pneumonia Dataset on Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data)  \n",
    "- **Content**: This dataset includes X-ray images categorized into two classes:  \n",
    "  - Pneumonia  \n",
    "  - Normal  \n",
    "- **Purpose**: This dataset has been utilized for solving the problem of detecting unknown classes in medical imaging, particularly focusing on distinguishing between pneumonia and normal cases.\n",
    "\n",
    "\n",
    "#### **X-ray Dataset(Tuberculosis-Normal)**\n",
    "- **Author**: Tapendu Karmakar  \n",
    "- **Source**: [Chest X-ray Dataset for Tuberculosis Segmentation](https://www.kaggle.com/datasets/iamtapendu/chest-x-ray-lungs-segmentation)  \n",
    "- **Content**: This dataset includes X-ray images categorized into two classes:  \n",
    "  - Tuberculosis  \n",
    "  - Normal  \n",
    "- **Purpose**: This dataset has been utilized for solving the problem of detecting unknown classes in medical imaging, particularly focusing on distinguishing between Tuberculosis and normal cases.\n",
    "\n",
    "#### **X-ray Dataset(Tuberculosis)**\n",
    "- **Author**: Tapendu Karmakar  \n",
    "- **Source**: [Tuberculosis (TB) Chest X-ray Database](https://www.kaggle.com/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset)  \n",
    "- **Content**: This dataset includes X-ray images categorized into two classes:  \n",
    "  - Tuberculosis  \n",
    "  - Normal  \n",
    "- **Conflict**  : Normal class is taken from [Chest X-ray Pneumonia Dataset on Kaggle](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia/data)\n",
    "- **Purpose**: This dataset has been utilized for Increase of data volume in Tuberculosis class \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include and update the info I have Taken tuberculosis data from :\n",
    "\n",
    "\"\"\" \n",
    "An official website of the United States government\n",
    "\n",
    "Here's how you know\n",
    "\n",
    "                                  PMC home page\n",
    "                              \n",
    "Search\n",
    "\n",
    "Log in\n",
    "Primary site navigation\n",
    "Search PMC Full-Text Archive\n",
    "Search PMC Full-Text Archive\n",
    "\n",
    "Search in PMC\n",
    "Advanced Search \n",
    "Journal List \n",
    "User Guide\n",
    "As a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with, the contents by NLM or the National Institutes of Health.\n",
    "Learn more: PMC Disclaimer | PMC Copyright Notice\n",
    "Quantitative Imaging in Medicine and Surgery logo\n",
    "Quant Imaging Med Surg. 2014 Dec;4(6):475–477. doi: 10.3978/j.issn.2223-4292.2014.11.20\n",
    "Two public chest X-ray datasets for computer-aided screening of pulmonary diseases\n",
    "Stefan Jaeger 1,✉, Sema Candemir 1, Sameer Antani 1, Yì-Xiáng J Wáng 2, Pu-Xuan Lu 3, George Thoma 1\n",
    "Author information\n",
    "Article notes\n",
    "Copyright and License information\n",
    "PMCID: PMC4256233  PMID: 25525580 \"\"\"\n",
    "\n",
    "\n",
    "and \n",
    "insights from \"\"\"\"Received September 27, 2020, accepted October 12, 2020, date of publication October 15, 2020, date of current version October 30, 2020.\n",
    "Digital Object Identifier 10.1109/ACCESS.2020.3031384\n",
    "Reliable Tuberculosis Detection Using Chest\n",
    "X-Ray With Deep Learning, Segmentation\n",
    "and Visualization\n",
    "TAWSIFUR RAHMAN 1\n",
    ", AMITH KHANDAKAR 2\n",
    ", (Senior Member, IEEE),\n",
    "MUHAMMAD ABDUL KADIR 1\n",
    ", KHANDAKER REJAUL ISLAM 3\n",
    ",\n",
    "KHANDAKAR F. ISLAM2\n",
    ", RASHID MAZHAR 4,5, TAHIR HAMID5,6\n",
    ",\n",
    "MOHAMMAD TARIQUL ISLAM 7\n",
    ", (Senior Member, IEEE), SAAD KASHEM8\n",
    ",\n",
    "ZAID BIN MAHBUB9\n",
    ", MOHAMED ARSELENE AYARI10, AND\n",
    "MUHAMMAD E. H. CHOWDHURY 2\n",
    ", (Senior Member, IEEE)\n",
    "1Department of Biomedical Physics and Technology, University of Dhaka, Dhaka 1000, Bangladesh\n",
    "2Department of Electrical Engineering, Qatar University, Doha 2713, Qatar\n",
    "3Department of Orthodontics, Bangabandhu Sheikh Mujib Medical University, Dhaka 1000, Bangladesh\n",
    "4Thoracic Surgery, Hamad General Hospital, Doha 3050, Qatar\n",
    "5Department of Medicine, Weill Cornell Medicine-Qatar, Doha 24811, Qatar\n",
    "6Cardiology, Hamad General Hospital, Doha 3050, Qatar\n",
    "7Department of Electrical, Electronic, and Systems Engineering, Universiti Kebangsaan Malaysia, Bangi 43600, Malaysia\n",
    "8Faculty of Robotics and Advanced Computing, Qatar Armed Forces-Academic Bridge Program, Qatar Foundation, Doha 24404, Qatar\n",
    "9Department of Mathematics and Physics, North South University, Dhaka 1229, Bangladesh\n",
    "10College of Engineering, Qatar University, Doha 2713, Qatar\n",
    "Corresponding author: Mohamed Arselene Ayari (arslana@qu.edu.qa)\n",
    "This work was made possible by NPRP12S-0227-190164 from the Qatar National Research Fund, a member of Qatar Foundation, Doha,\n",
    "Qatar. Open Access funding provided by the Qatar National Library :A. DATASETS DESCRIPTION\n",
    "1) LUNG SEGMENTATION\n",
    "In this work, Kaggle Chest X-ray images and corresponding\n",
    "lung mask dataset [69] were used for training the lung segmentation models, where 704 X-ray images and their corresponding ground truth lung masks are available. All masks\n",
    "VOLUME 8, 2020 191589\n",
    "T. Rahman et al.: Reliable TB Detection Using CXR With Deep Learning, Segmentation, and Visualizatio\n",
    "FIGURE 1. Architecture of A) original U-Net and B) modified U-Net.\n",
    "FIGURE 2. Score-CAM heat map on a chest X-ray image showing that\n",
    "different regions of the image were used in decision making by the CNN.\n",
    "were annotated by expert radiologists; sample X-ray images\n",
    "and masks are shown in Figure 4. There are 360 normal\n",
    "X-ray images and 344 abnormal (infected lung) X-ray images\n",
    "available in the dataset. Therefore, U-Net networks were\n",
    "trained with both normal and abnormal images.\n",
    "2) TB CLASSIFICATION\n",
    "Four publicly accessible databases were used for TB classification problem. These are NLM dataset, Belarus dataset,\n",
    "NIAID TB dataset and RSNA dataset:\n",
    "NLM dataset: National Library of Medicine (NLM)\n",
    "in U.S. [25] has made two lung X-ray datasets publicly\n",
    "available: the Montgomery and Shenzhen datasets. The\n",
    "Montgomery County (MC) and the Shenzhen, China (CHN)\n",
    "databases are comprised of 138 and 667 posterior-anterior\n",
    "(PA) chest X-ray images respectively. The resolution of\n",
    "the images of MC database was either 4, 020 × 4.892\n",
    "or 4, 892 × 4.020 pixels whereas that for CHN database\n",
    "was variable but around 3000 × 3000 pixels. In the MC\n",
    "database, out of 138 chest X-ray images, 58 images were\n",
    "taken from different TB patients and 80 images were from\n",
    "normal subjects. In the CHN database, out of 662 chest X-ray\n",
    "images, 336 images were taken from different TB patients\n",
    "191590 VOLUME 8, 2020\n",
    "T. Rahman et al.: Reliable TB Detection Using CXR With Deep Learning, Segmentation, and Visualizatio\n",
    "FIGURE 3. Overview of the complete system.\n",
    "FIGURE 4. Example of X-ray images and corresponding ground truth lung\n",
    "masks from Kaggle dataset.\n",
    "and 324 images were from normal subjects. Therefore, in this\n",
    "NLM database, there are 406 normal and 394 TB infected\n",
    "X-ray images.\n",
    "Belarus dataset: Belarus Set [70] was collected for a\n",
    "drug resistance study initiated by the National Institute of\n",
    "Allergy and Infectious Diseases, Ministry of Health, Republic of Belarus. The dataset contains 306 CXR images of\n",
    "169 patients. Chest radiographs were taken using the Kodak\n",
    "Point-of-Care 260 system and the resolution of the images\n",
    "was 2248 × 2248 pixels. All the images of this database are\n",
    "TB infected images.\n",
    "NIAID TB dataset: NIAID TB portal program dataset [71],\n",
    "which contains about 3000 TB positive CXR images from\n",
    "about 3087 cases. All images were collected from seven\n",
    "different countries and all images are in Portable Network\n",
    "Graphics (PNG) format. In this study, we have used 2800 TB\n",
    "positive CXR images out of 3000 images. 200 poor quality\n",
    "images were discarded from this database.\n",
    "RSNA CXR dataset: RSNA pneumonia detection challenge dataset [72], which is comprised of about 30,000 chest\n",
    "X-ray images, where 10,000 images are normal and others are\n",
    "abnormal and lung opacity images. All images are in Digital\n",
    "Imaging and Communications in Medicine (DICOM) format.\n",
    "To create a normal database of 3,500 chest X-ray images for\n",
    "this study, 3,094 normal images were taken from this database\n",
    "and rest of the 406 normal images were taken from the\n",
    "NLM database. However, the number of TB infected images\n",
    "by combining NLM and Belarus dataset was 700 and from\n",
    "NIAID TB dataset was 2800. In total, there were 3500 TB\n",
    "infected and 3500 normal X-ray images were used in th\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "as well as \n",
    "\"\"\"\n",
    "Tapendu Karmakar · Updated a month ago\n",
    "\n",
    "New Notebook\n",
    "\n",
    "Download\n",
    "\n",
    "Chest X-ray Dataset for Tuberculosis Segmentation\n",
    "Chest X-ray Organized Lung Segmentation Masks\n",
    "\n",
    "source \"https://www.kaggle.com/datasets/iamtapendu/chest-x-ray-lungs-segmentation\" \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: NORMAL, Total: 5180, Train: 4870, Val: 51, Test: 259\n",
      "Category: PNEUMONIA, Total: 3883, Train: 3651, Val: 38, Test: 194\n",
      "Category: UNKNOWN, Total: 1357, Train: 1277, Val: 13, Test: 67\n",
      "Category: TUBERCULOSIS, Total: 968, Train: 911, Val: 9, Test: 48\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": false,
    "execution": {
     "iopub.execute_input": "2024-11-21T18:27:01.853578Z",
     "iopub.status.busy": "2024-11-21T18:27:01.853256Z",
     "iopub.status.idle": "2024-11-21T18:27:07.307601Z",
     "shell.execute_reply": "2024-11-21T18:27:07.306927Z",
     "shell.execute_reply.started": "2024-11-21T18:27:01.853546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 13028, Validation set size: 761, Test set size: 1527\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Modify the create_dataset function to include \"UNKNOWN\" category\n",
    "def create_dataset(folder_path):\n",
    "    my_list = []\n",
    "    for category in ['NORMAL', 'PNEUMONIA', 'UNKNOWN', 'TUBERCULOSIS']:\n",
    "        category_path = os.path.join(folder_path, category)\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            # Ensure we're only adding image files\n",
    "            if os.path.isfile(file_path) and file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                my_list.append([file_path, category])\n",
    "    return pd.DataFrame(my_list, columns=['file_path', 'label'])\n",
    "\n",
    "# Dataset paths\n",
    "dataset_dir = r\"D:\\source\\data\\data\"\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "val_dir = os.path.join(dataset_dir, 'val')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Create DataFrames for train, validation, and test datasets\n",
    "train_df = create_dataset(train_dir)\n",
    "val_df = create_dataset(val_dir)\n",
    "test_df = create_dataset(test_dir)\n",
    "\n",
    "# Convert labels to numeric: NORMAL -> 0, PNEUMONIA -> 1, UNKNOWN -> 2\n",
    "train_df['label'] = train_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2 , 'TUBERCULOSIS': 3})\n",
    "val_df['label'] = val_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2, 'TUBERCULOSIS': 3})\n",
    "test_df['label'] = test_df['label'].map({'NORMAL': 0, 'PNEUMONIA': 1, 'UNKNOWN': 2, 'TUBERCULOSIS': 3})\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train set size: {len(train_df)}, Validation set size: {len(val_df)}, Test set size: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Counts per Category:\n",
      "Train set:\n",
      "  NORMAL: 4667\n",
      "  PNEUMONIA: 3633\n",
      "  UNKNOWN: 1155\n",
      "  TUBERCULOSIS: 3573\n",
      "Validation set:\n",
      "  NORMAL: 274\n",
      "  PNEUMONIA: 213\n",
      "  UNKNOWN: 67\n",
      "  TUBERCULOSIS: 207\n",
      "Test set:\n",
      "  NORMAL: 548\n",
      "  PNEUMONIA: 427\n",
      "  UNKNOWN: 135\n",
      "  TUBERCULOSIS: 417\n"
     ]
    }
   ],
   "source": [
    "# Function to count categories in a given DataFrame\n",
    "def count_categories(df, dataset_name):\n",
    "    category_counts = df['label'].value_counts()\n",
    "    print(f\"{dataset_name} set:\")\n",
    "    print(f\"  NORMAL: {category_counts.get(0, 0)}\")  # NORMAL = 0\n",
    "    print(f\"  PNEUMONIA: {category_counts.get(1, 0)}\")  # PNEUMONIA = 1\n",
    "    print(f\"  UNKNOWN: {category_counts.get(2, 0)}\")  # UNKNOWN = 2 (added the UNKNOWN category)\n",
    "    print(f\"  TUBERCULOSIS: {category_counts.get(3, 0)}\")  # TUBERCULOSIS = 3\n",
    "\n",
    "# Count and display for train, validation, and test datasets\n",
    "print(\"Image Counts per Category:\")\n",
    "count_categories(train_df, \"Train\")\n",
    "count_categories(val_df, \"Validation\")\n",
    "count_categories(test_df, \"Test\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 408\n",
      "Validation dataset size: 24\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Define Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 0]  # Image path\n",
    "        label = self.dataframe.iloc[idx, 1]     # Image label (NORMAL, PNEUMONIA, UNKNOWN)\n",
    "        img = Image.open(img_path).convert('RGB')  # Convert the image to RGB if not already\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "\n",
    "train_transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 for ResNet-18 input size\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flip\n",
    "    transforms.RandomRotation(5),  # Slight rotation between -5 and +5 degrees\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "\n",
    "val_transform_resnet = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert grayscale to RGB (3 channels)\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ResNet\n",
    "])\n",
    "\n",
    "# Assuming train_df and val_df are already created with 'file_path' and 'label' columns\n",
    "train_dataset_resnet = ImageDataset(train_df, transform=train_transform_resnet)\n",
    "val_dataset_resnet = ImageDataset(val_df, transform=val_transform_resnet)\n",
    "\n",
    "# DataLoader - For training and validation datasets\n",
    "batch_size = 32\n",
    "\n",
    "train_loader_resnet = DataLoader(train_dataset_resnet, batch_size=batch_size, shuffle=True)\n",
    "val_loader_resnet = DataLoader(val_dataset_resnet, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Optionally print dataset sizes\n",
    "print(f\"Training dataset size: {len(train_loader_resnet)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader_resnet)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for multi-GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "# Function to prepare model for multi-GPU usage\n",
    "def prepare_model_for_multigpu(model):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Training function with TensorBoard logging and history tracking\n",
    "def train_model_with_history_and_tensorboard(model, train_loader, val_loader, criterion, optimizer, num_epochs=30, device='cuda'):\n",
    "    # Ensure model is moved to the correct device (GPU/CPU)\n",
    "    model.to(device)\n",
    "\n",
    "    # Initialize TensorBoard writer\n",
    "    writer = SummaryWriter(log_dir='tensorboard_logs')\n",
    "\n",
    "    # Track training and validation losses and accuracies\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # Load model weights (if resuming from a pre-trained model)\n",
    "    if os.path.exists('model/model_29.pt'):\n",
    "        model.load_state_dict(torch.load('model/model_29.pt', map_location=device))\n",
    "        print(\"Model weights loaded successfully.\")\n",
    "    else:\n",
    "        print(\"No pre-trained weights found, starting from scratch.\")\n",
    "    \n",
    "    model_dir = 'model'\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    # Training loop for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        start_epoch_time = time.time()  # Start time for the epoch\n",
    "\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # Training loop\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track running loss and accuracy\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate training loss and accuracy\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Start time for validation phase\n",
    "        start_val_time = time.time()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Calculate validation loss and accuracy\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # End time for validation phase\n",
    "        end_val_time = time.time()\n",
    "        validation_time = end_val_time - start_val_time\n",
    "\n",
    "        # Calculate total time for the epoch\n",
    "        end_epoch_time = time.time()\n",
    "        epoch_time = end_epoch_time - start_epoch_time\n",
    "\n",
    "        # Print results for the epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "                f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}% | \"\n",
    "                f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}% | \"\n",
    "                f\"Epoch Time: {epoch_time:.2f}s | Validation Time: {validation_time:.2f}s\")\n",
    "\n",
    "        # Log metrics to TensorBoard\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Validation', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/Train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/Validation', val_accuracy, epoch)\n",
    "        writer.add_scalar('Time/Epoch', epoch_time, epoch)\n",
    "        writer.add_scalar('Time/Validation', validation_time, epoch)\n",
    "\n",
    "        # Save the model after every epoch (ensure the directory exists)\n",
    "        torch.save(model.state_dict(), f'{model_dir}/model_{epoch}.pt')\n",
    "\n",
    "    # Close the TensorBoard writer\n",
    "    writer.close()\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies\n",
    "\n",
    "# Example usage of the function\n",
    "# Make sure your DataLoader objects (train_loader, val_loader) and model are defined\n",
    "class_weights = [.70, 0.90, 1.0, 1.0]  \n",
    "# Convert class weights to a tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define the weighted CrossEntropy loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {np.int64(0): np.float64(0.6978787229483608), np.int64(1): np.float64(0.896504266446463), np.int64(2): np.float64(2.8199134199134197), np.int64(3): np.float64(0.9115589140778058)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Sample class distribution based on the dataset\n",
    "class_labels = np.array([0, 1, 2 , 3])  # Example class labels\n",
    "y_train = np.array([0]*4667 + [1]*3633 + [2]*1155 + [3]*3573)  # Example training set distribution\n",
    "\n",
    "# Calculate class weights using sklearn\n",
    "class_weights = compute_class_weight('balanced', classes=class_labels, y=y_train)\n",
    "\n",
    "print(f\"Class weights: {dict(zip(class_labels, class_weights))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rifat\\miniconda3\\envs\\mlweb\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\rifat\\miniconda3\\envs\\mlweb\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained ResNet-18 model\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 4)  # Modify for binary classification\n",
    "resnet18 = prepare_model_for_multigpu(resnet18)  # Apply multi-GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pretrained ResNet-18 Model...\n",
      "No pre-trained weights found, starting from scratch.\n",
      "Epoch [1/60] Train Loss: 0.1452, Train Acc: 94.17% | Val Loss: 0.2122, Val Acc: 91.20% | Epoch Time: 244.38s | Validation Time: 12.80s\n",
      "Epoch [2/60] Train Loss: 0.0818, Train Acc: 96.73% | Val Loss: 0.1319, Val Acc: 94.74% | Epoch Time: 241.64s | Validation Time: 12.85s\n",
      "Epoch [3/60] Train Loss: 0.0676, Train Acc: 97.48% | Val Loss: 0.0852, Val Acc: 95.93% | Epoch Time: 247.88s | Validation Time: 13.22s\n",
      "Epoch [4/60] Train Loss: 0.0622, Train Acc: 97.54% | Val Loss: 0.0722, Val Acc: 97.50% | Epoch Time: 249.32s | Validation Time: 12.91s\n",
      "Epoch [5/60] Train Loss: 0.0501, Train Acc: 98.09% | Val Loss: 0.0614, Val Acc: 98.03% | Epoch Time: 242.23s | Validation Time: 12.58s\n",
      "Epoch [6/60] Train Loss: 0.0447, Train Acc: 98.17% | Val Loss: 0.3728, Val Acc: 92.64% | Epoch Time: 242.93s | Validation Time: 12.73s\n",
      "Epoch [7/60] Train Loss: 0.0411, Train Acc: 98.41% | Val Loss: 0.0592, Val Acc: 98.03% | Epoch Time: 258.03s | Validation Time: 15.66s\n",
      "Epoch [8/60] Train Loss: 0.0370, Train Acc: 98.70% | Val Loss: 0.0651, Val Acc: 97.37% | Epoch Time: 326.92s | Validation Time: 12.92s\n",
      "Epoch [9/60] Train Loss: 0.0469, Train Acc: 98.26% | Val Loss: 0.0499, Val Acc: 98.55% | Epoch Time: 255.47s | Validation Time: 12.77s\n",
      "Epoch [10/60] Train Loss: 0.0270, Train Acc: 99.02% | Val Loss: 0.0986, Val Acc: 96.85% | Epoch Time: 251.43s | Validation Time: 12.69s\n",
      "Epoch [11/60] Train Loss: 0.0255, Train Acc: 98.95% | Val Loss: 0.0722, Val Acc: 97.77% | Epoch Time: 251.88s | Validation Time: 12.60s\n",
      "Epoch [12/60] Train Loss: 0.0257, Train Acc: 98.97% | Val Loss: 0.0843, Val Acc: 97.37% | Epoch Time: 251.17s | Validation Time: 12.84s\n",
      "Epoch [13/60] Train Loss: 0.0278, Train Acc: 99.09% | Val Loss: 0.1540, Val Acc: 94.48% | Epoch Time: 258.75s | Validation Time: 13.02s\n",
      "Epoch [14/60] Train Loss: 0.0281, Train Acc: 98.95% | Val Loss: 0.0574, Val Acc: 98.03% | Epoch Time: 261.82s | Validation Time: 13.58s\n",
      "Epoch [15/60] Train Loss: 0.0223, Train Acc: 99.12% | Val Loss: 0.0670, Val Acc: 97.63% | Epoch Time: 266.31s | Validation Time: 13.15s\n",
      "Epoch [16/60] Train Loss: 0.0189, Train Acc: 99.24% | Val Loss: 0.0533, Val Acc: 98.55% | Epoch Time: 268.89s | Validation Time: 13.73s\n",
      "Epoch [17/60] Train Loss: 0.0179, Train Acc: 99.29% | Val Loss: 0.1048, Val Acc: 96.58% | Epoch Time: 269.38s | Validation Time: 13.42s\n",
      "Epoch [18/60] Train Loss: 0.0141, Train Acc: 99.52% | Val Loss: 0.0411, Val Acc: 99.08% | Epoch Time: 270.24s | Validation Time: 13.43s\n",
      "Epoch [19/60] Train Loss: 0.0209, Train Acc: 99.27% | Val Loss: 0.0825, Val Acc: 98.16% | Epoch Time: 270.67s | Validation Time: 13.28s\n",
      "Epoch [20/60] Train Loss: 0.0190, Train Acc: 99.37% | Val Loss: 0.0873, Val Acc: 97.24% | Epoch Time: 270.99s | Validation Time: 13.36s\n",
      "Epoch [21/60] Train Loss: 0.0149, Train Acc: 99.49% | Val Loss: 0.1943, Val Acc: 96.19% | Epoch Time: 272.52s | Validation Time: 13.14s\n",
      "Epoch [22/60] Train Loss: 0.0153, Train Acc: 99.44% | Val Loss: 0.0739, Val Acc: 98.69% | Epoch Time: 265.50s | Validation Time: 13.24s\n",
      "Epoch [23/60] Train Loss: 0.0158, Train Acc: 99.39% | Val Loss: 0.0725, Val Acc: 98.16% | Epoch Time: 261.03s | Validation Time: 13.53s\n",
      "Epoch [24/60] Train Loss: 0.0164, Train Acc: 99.46% | Val Loss: 0.1705, Val Acc: 94.48% | Epoch Time: 267.01s | Validation Time: 13.50s\n",
      "Epoch [25/60] Train Loss: 0.0194, Train Acc: 99.37% | Val Loss: 0.0800, Val Acc: 97.90% | Epoch Time: 266.90s | Validation Time: 13.49s\n",
      "Epoch [26/60] Train Loss: 0.0156, Train Acc: 99.39% | Val Loss: 0.0745, Val Acc: 97.63% | Epoch Time: 271.14s | Validation Time: 13.74s\n",
      "Epoch [27/60] Train Loss: 0.0133, Train Acc: 99.59% | Val Loss: 0.0634, Val Acc: 97.90% | Epoch Time: 254.68s | Validation Time: 12.55s\n",
      "Epoch [28/60] Train Loss: 0.0219, Train Acc: 99.18% | Val Loss: 0.0506, Val Acc: 98.55% | Epoch Time: 265.45s | Validation Time: 14.43s\n",
      "Epoch [29/60] Train Loss: 0.0104, Train Acc: 99.56% | Val Loss: 0.0521, Val Acc: 98.42% | Epoch Time: 265.97s | Validation Time: 13.25s\n",
      "Epoch [30/60] Train Loss: 0.0092, Train Acc: 99.72% | Val Loss: 0.0819, Val Acc: 97.50% | Epoch Time: 260.51s | Validation Time: 12.87s\n",
      "Epoch [31/60] Train Loss: 0.0162, Train Acc: 99.44% | Val Loss: 0.1099, Val Acc: 97.50% | Epoch Time: 258.34s | Validation Time: 13.23s\n",
      "Epoch [32/60] Train Loss: 0.0156, Train Acc: 99.39% | Val Loss: 0.0453, Val Acc: 98.82% | Epoch Time: 249.44s | Validation Time: 12.85s\n",
      "Epoch [33/60] Train Loss: 0.0127, Train Acc: 99.57% | Val Loss: 0.0513, Val Acc: 98.69% | Epoch Time: 245.15s | Validation Time: 13.18s\n",
      "Epoch [34/60] Train Loss: 0.0096, Train Acc: 99.65% | Val Loss: 0.0465, Val Acc: 98.82% | Epoch Time: 244.60s | Validation Time: 12.66s\n",
      "Epoch [35/60] Train Loss: 0.0069, Train Acc: 99.77% | Val Loss: 0.0552, Val Acc: 98.42% | Epoch Time: 276.78s | Validation Time: 17.53s\n",
      "Epoch [36/60] Train Loss: 0.0128, Train Acc: 99.50% | Val Loss: 0.0607, Val Acc: 98.69% | Epoch Time: 285.61s | Validation Time: 12.57s\n",
      "Epoch [37/60] Train Loss: 0.0090, Train Acc: 99.65% | Val Loss: 0.0620, Val Acc: 98.42% | Epoch Time: 256.74s | Validation Time: 12.96s\n",
      "Epoch [38/60] Train Loss: 0.0212, Train Acc: 99.26% | Val Loss: 0.1035, Val Acc: 98.29% | Epoch Time: 254.52s | Validation Time: 12.67s\n",
      "Epoch [39/60] Train Loss: 0.0075, Train Acc: 99.77% | Val Loss: 0.0764, Val Acc: 98.55% | Epoch Time: 249.82s | Validation Time: 12.75s\n",
      "Epoch [40/60] Train Loss: 0.0062, Train Acc: 99.78% | Val Loss: 0.0765, Val Acc: 98.42% | Epoch Time: 248.28s | Validation Time: 12.39s\n",
      "Epoch [41/60] Train Loss: 0.0080, Train Acc: 99.72% | Val Loss: 0.0814, Val Acc: 98.55% | Epoch Time: 254.00s | Validation Time: 12.89s\n",
      "Epoch [42/60] Train Loss: 0.0066, Train Acc: 99.79% | Val Loss: 0.0908, Val Acc: 98.03% | Epoch Time: 255.10s | Validation Time: 12.55s\n",
      "Epoch [43/60] Train Loss: 0.0078, Train Acc: 99.75% | Val Loss: 0.0508, Val Acc: 98.69% | Epoch Time: 252.12s | Validation Time: 13.20s\n",
      "Epoch [44/60] Train Loss: 0.0165, Train Acc: 99.39% | Val Loss: 0.0935, Val Acc: 97.63% | Epoch Time: 261.91s | Validation Time: 12.90s\n",
      "Epoch [45/60] Train Loss: 0.0076, Train Acc: 99.70% | Val Loss: 0.0678, Val Acc: 98.55% | Epoch Time: 251.90s | Validation Time: 13.10s\n",
      "Epoch [46/60] Train Loss: 0.0101, Train Acc: 99.69% | Val Loss: 0.0849, Val Acc: 98.69% | Epoch Time: 249.90s | Validation Time: 12.07s\n",
      "Epoch [47/60] Train Loss: 0.0076, Train Acc: 99.73% | Val Loss: 0.0781, Val Acc: 98.42% | Epoch Time: 254.12s | Validation Time: 13.11s\n",
      "Epoch [48/60] Train Loss: 0.0104, Train Acc: 99.73% | Val Loss: 0.0938, Val Acc: 97.77% | Epoch Time: 250.13s | Validation Time: 12.78s\n",
      "Epoch [49/60] Train Loss: 0.0320, Train Acc: 99.47% | Val Loss: 0.0700, Val Acc: 97.77% | Epoch Time: 253.75s | Validation Time: 12.69s\n",
      "Epoch [50/60] Train Loss: 0.0122, Train Acc: 99.57% | Val Loss: 0.0808, Val Acc: 97.37% | Epoch Time: 249.97s | Validation Time: 12.53s\n",
      "Epoch [51/60] Train Loss: 0.0080, Train Acc: 99.69% | Val Loss: 0.0412, Val Acc: 98.55% | Epoch Time: 249.90s | Validation Time: 13.78s\n",
      "Epoch [52/60] Train Loss: 0.0076, Train Acc: 99.69% | Val Loss: 0.0714, Val Acc: 98.42% | Epoch Time: 252.97s | Validation Time: 12.24s\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer for ResNet-18\n",
    "optimizer_resnet = optim.Adam(resnet18.parameters(), lr=0.0001)\n",
    "\n",
    "# Train the Pretrained ResNet-18 Model\n",
    "print(\"Training Pretrained ResNet-18 Model...\")\n",
    "train_losses_resnet, val_losses_resnet, train_accuracies_resnet, val_accuracies_resnet = train_model_with_history_and_tensorboard(\n",
    "    resnet18, train_loader_resnet, val_loader_resnet, criterion, optimizer_resnet, num_epochs=60\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "mlweb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
